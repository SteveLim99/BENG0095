{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Introduction to Data Handling in Python\n",
    "\n",
    "This is a very brief introduction to data handling, and possibly revision for many of you.  \n",
    "Please note that some of the code demonstrated below is going to be used in later exercises during the module.\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "First, we import libraries: NumPy (`numpy`), Pandas (`pandas`), and Scikit-learn (`sklearn`) are the main libraries we will be working with.\n",
    "- NumPy is a library adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "- Pandas is a library for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
    "- Scikit-learn is a machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Scikit-learn, we import only selected items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We installed NumPy, Pandas and Scikit-learn on the top of standard Python installation.  \n",
    "Python itself also has a standard library which does not require additional installation. \n",
    "You may find some of the modules useful in the future, but we will not be importing them in this notebook:\n",
    "https://docs.python.org/3/library/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Iris data set' is included in Scikit-learn, and is a well-known data set commonly used when teaching machine learning.  \n",
    "We load it below.   \n",
    "Round brackets are used mainly for function arguments.  \n",
    "Square brackets are used mainly in the context of indexing and slicing (here, accessing elements of a collection). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print details of the Iris data set:  \n",
    "We  can print using the standard Python `print()` function, but in a Jupyter Notebook, the value of the last item in the code cell is automatically printed.  \n",
    "Automatic printing can be supressed with `;`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explore the data set in more detail:\n",
    "\n",
    "- We can print feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can print data dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign the `shape` of the data set to variables, (we can use them later to iterate over the dataset):\n",
    "\n",
    "`X.shape` returns a two-element array, where `X.shape[0]` is the number of rows (samples), and `X.shape[1]` is the number of columns (features).  \n",
    "(Please note that indexing starts at 0; row and column indexing also starts at 0).  \n",
    "  \n",
    "The code below is equivalent to:  \n",
    "`n_sample = X.shape[0]`  \n",
    "`n_feature = X.shape [1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample, n_feature = X.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select columns and rows in the dataset. \n",
    "\n",
    "Rows are selected before the comma, columns after the comma. Note that this corresponds with the order of elements decribing shape. This row, column order is consistent in Python. \n",
    "\n",
    "You will encounter objects with more than 2 dimensions, these will be described using one number per axis, e.g. `X[:, :, :, :]` for four dimensions.    \n",
    "  \n",
    "Let's select the first row: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0, :] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When selecting adjacent rows / columns, use `:` to separate the start and end of the slice. \n",
    "\n",
    "When selecting multiple non-adjacent rows / columns, use `,` between them, and wrap the whole selction in square brackets.    \n",
    "  \n",
    "Let's select first three rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the first column, then save it to a variable for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = X[:, 0] \n",
    "print(first_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate average 'sepal length' (feature 0) by hand:  \n",
    "  \n",
    "The notation `x += y` is a shorthand for `x = x + y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for item in range(n_sample):\n",
    "    total += X[item, 0] \n",
    "    \n",
    "avg = total / n_sample\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used a `for` loop, these are used to iterate over a sequence. If you are not familiar with them, you can find information here: https://www.w3schools.com/python/python_for_loops.asp\n",
    "\n",
    "Other common ways of controlling flow of your code are `if`, `elif` and `else` statements. More information can be found here: https://www.w3schools.com/python/python_conditions.asp  \n",
    "\n",
    "If we think we will be using the above code again, we can put it into a function which calculates the average of a vector. Then we pass all the required arguments to the function and return the result.  \n",
    "\n",
    "Since we need to pass the vector as an argument anyway, we can calculate its length inside the function.  \n",
    "(Note that we switched from operating in two dimensions when working with the whole multidimensional array above, to operating in one dimension below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_vector(vector): #function definition\n",
    "    total = 0\n",
    "    n_sample = len(vector)\n",
    "    for item in range(n_sample):\n",
    "        total += vector[item]\n",
    "    \n",
    "    avg = total / n_sample\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sepal_len = avg_vector(first_col) #function call\n",
    "print(avg_sepal_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the function to calculate the average of another column: 'sepal width':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sepal_width = avg_vector(X[:, 1])\n",
    "print(avg_sepal_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need custom functions in the future, however we should leverage existing Python functions and use the imported libraries to avoid having to write code for common operations - like averaging - from scratch.\n",
    "\n",
    "Simple functions exist in Python by default, and frequently also exist as a part of more advanced libraries like NumPy. You will encounter both versions, but try to make consistent choices in your own code.     \n",
    "  \n",
    "The Python `mean()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_avg = first_col.mean()\n",
    "print(py_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, `axis = 0` specifies column-wise operation, whereas `axis = 1` would specify row-wise operation. When using new functions, check documentation to see what arguments they can take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_avg_by_col = X.mean(axis = 0)\n",
    "print(py_avg_by_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equivalent function exists in NumPy:  \n",
    "(You can check documentation of NumPy average function here:  \n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_avg = np.average(first_col)\n",
    "print(np_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_avg_by_col = np.average(X, axis = 0)\n",
    "print(np_avg_by_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristic NumPy features include multidimensional array objects called `ndarray`'s and functions which work with them. Examples are available here: https://docs.scipy.org/doc/numpy/user/quickstart.html  \n",
    "\n",
    "In fact the Iris data set we encountered earlier contains NumPy array objects.  \n",
    "\n",
    "We can check it using `type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = type(iris.data)\n",
    "dataset_dimensions = iris.data.ndim\n",
    "dataset_shape = iris.data.shape\n",
    "print(\"Iris dataset is of type %s, has %d dimensions, %d rows and %d columns.\\n\" % (dataset_type, dataset_dimensions, dataset_shape[0], dataset_shape[1]))\n",
    "\n",
    "col_type = type(first_col)\n",
    "col_dimensions = first_col.ndim\n",
    "col_shape = first_col.shape\n",
    "print(\"A single column is of type %s, has %d dimension, and %d rows.\\n\" % (col_type, col_dimensions, col_shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you would like to make changes to the data, but also want to keep the original data for reference, you can create a copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with a selection of your values: \n",
    "\n",
    "1) Create a mask for your data: This has the same shape as your data, and contains Boolean values (True / False) indicating whether a given value in the data set fulfills the condition.  \n",
    "\n",
    "2) Use the mask to perform operations only on the selected values from your data set.\n",
    "\n",
    "Below, we select all elements of `X_copy` which are larger than 5.0, then replace them with `nan` using NumPy a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (X_copy > 5.0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then replace values which were larger than 5.0 with `nan`. `nan` stands for \"not a number\", and is commonly used to indicate undefined values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy[mask] = np.nan\n",
    "print(X_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice you will most likely be removing or replacing `nan` in your data set.  \n",
    "\n",
    "The NumPy `isnan()` function returns a Boolean value describing whether the object is `nan`.  \n",
    "\n",
    "Below, we use it inside the NumPy `any()` function. Together, this will return `True` for all rows which contain at least one `nan`, and `False` for those which do not contain any `nan`.  \n",
    "\n",
    "Next, we remove all rows with `nan` from the data set. \n",
    "\n",
    "In the future, we will cover strategies such as replacing `nan` with feature's average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_nan = np.any(np.isnan(X_copy), axis=1)\n",
    "X_copy = X_copy[~mask_nan]\n",
    "print(X_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also use the NumPy `nan_to_num()` function: https://docs.scipy.org/doc/numpy/reference/generated/numpy.nan_to_num.html   \n",
    "\n",
    "Pandas library (descibed in more detail below) provides, amongst other things, the `dropna()` function for removing undefined data.\n",
    "\n",
    "There exists redundancy and more than one way to achieve the same result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will frequently work with Pandas data frames.  \n",
    "\n",
    "When creating data frame objects, `_df` is frequently added to an object's name for clarity, or the object is simply called `df`.  \n",
    "\n",
    "Empty frame can be created as follows by not providing values for data and columns:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame() \n",
    "print(empty_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we fill the frame with random integers in range 0 to 10, arranged in 100 rows and 3 columns.\n",
    "\n",
    "By default, `df.head()` prints the first five rows of the data frame. This is handy when we want to check the data frame, but we do not want to print all rows. Arguments can be used to select the number of printed rows and the starting line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"age\", \"blood_pressure\", \"weight\"]\n",
    "my_data = np.random.randint(low = 0, high = 10,size=(100, 3))\n",
    "df1 = pd.DataFrame(data = my_data, columns = labels)\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further syntax for creating data frames is shown below. \n",
    "\n",
    "To initialise an empty data frame only with labels, use:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty2_df = pd.DataFrame({\"age\" : [], \"blood_pressure\" : [], \"weight\" : []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a data frame with content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"age\" : np.random.randint(0,99,size=100), \"blood_pressure\" : np.random.randint(60,150,size=100), \"weight\" : np.random.randint(50,120,size=100)})\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check details of the data frame using the `df.info()` function, where `df` is replaced with the name of your data frame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic statistical analysis of Pandas dataframes can be performed by using the `df.describe()` function.  \n",
    "You should always look at your data and do common sense checks before you feed it into machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both column names and indices (accessed using `iloc[ ]`) can be used to select dataframe columns.  \n",
    "\n",
    "A single set of square brackets is required when using one column name, and two sets of square brackets are required when using multiple names. For example:  \n",
    "`df2[\"age\"]`  \n",
    "`df2[[\"age\", \"weight\"]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[\"age\", \"weight\"]].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[:, [0, 2]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.iloc[ ]` can also be used to select rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving and Reading Data\n",
    "### Checking the Working Directory\n",
    "First, lets check which directory we are currently working in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files will be saved here, unless the full file path is provided. \n",
    "\n",
    "We can change the working directory (for this we need to import os library): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_path = \"/home/dariush/Desktop\" # replace with your path\n",
    "os.chdir(my_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Files\n",
    "One of the ways to save your data is by using the Pandas `df.to_csv()` function. \n",
    "\n",
    "We create a tab-separated file (`\\t`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"my_file.csv\" # if you want to be on the safe side, you can pass the whole path, i.e. directory + file_name\n",
    "df2.to_csv(file_name,index=False) # we are saving it without the index column. We do not really need it (it was just numbering), and it is going to be recreated when we open the file below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read a file we can use the Pandas `read_csv()` function. It can take many useful arguments, for example to indicate the delimiter used (such as commas or tabs), to skip blank lines, etc. \n",
    "\n",
    "Documentation can be found here: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_saved_file_name = \"my_file.csv\"\n",
    "new_df = pd.read_csv(my_saved_file_name)\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Note\n",
    "Please remember that most data scientists Google things all the time: Libraries change; problems we are facing have already been solved by someone else.  \n",
    "The 'Stack Overflow' site is a useful source of problem solutions and code examples.  \n",
    "Remember that using documentation, libraries and copying small chunks of code (if not restricted by law) is OK...although this should always be referenced where appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
